---
title: "An Efficient Convolutional Multi-Scale Vision Transformer for Image Classification"
collection: publications
permalink: /publication/2023-11-3-paper-An Efficient Convolutional Multi-Scale Vision Transformer for Image Classification-2
excerpt:  ''
date: 2023-11-3
venue: '2023 International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)'
slidesurl: # 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=SBoHvVQAAAAJ&citation_for_view=SBoHvVQAAAAJ:u-x6o8ySG0sC'
citation: 'Zhang J, Chen Z, Ge Y, et al. An Efficient Convolutional Multi-Scale Vision Transformer for Image Classification[C]//2023 International Conference on Image Processing, Computer Vision and Machine Learning (ICICML). IEEE, 2023: 344-347.'
---

This paper introduces an innovative and efficient multi-scale Vision Transformer (ViT) for the task of image classification. The proposed model leverages the inherent power of transformer architecture and combines it with the concept of multi-scale processing generally used in convolutional neural networks (CNNs). The work aims to address the limitations of conventional ViTs which typically operate at a single scale, hence overlooking the hierarchical structure in visual data. The multi-scale ViT enhances classification performance by processing image features at different scales, effectively capturing both low-level and high-level semantic information. Extensive experimental results demonstrate the superior performance of the proposed model over standard ViTs and other state-of-the-art image classification methods, signifying the effectiveness of the multi-scale approach. This research opens new avenues for incorporating scale-variance in transformer-based models for improved performance in vision tasks.
